{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e035dca4",
   "metadata": {},
   "source": [
    "### Doublet identification & filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec4ec4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scvi\n",
    "import hdf5plugin\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b5f457",
   "metadata": {},
   "source": [
    "- Οι περισσότερες τεχνολογίες που χρησιμοποιούνται για scRNA sequencing είναι droplet-based.\n",
    "\n",
    "- Πρόκειται για μικρο-σταγονίδια που περιλαμβάνουν μόρια ανιχνευτές (DNA barcodes). Σε αυτά απομονώνται μεμονωμένα κύτταρα το περιεχόμενο των οποίων στη συνέχεια θα υποστεί αλληλούχιση επόμενης γενιάς (Next Generation Sequencing).\n",
    "\n",
    "- Σε κάποιες περιπτώσεις, από λάθος γίνεται απομόνωση δύο κυττάρων (2) σε ένα μικρο-σταγονίδιο. Έτσι δημιουργούνται τα doublets.\n",
    "\n",
    "- Τα doublets μπορεί να είναι ομοτυπικά (δηλαδή: τα προφίλ έκφρασης των δύο κυττάρων είναι παρόμοια) ή ετεροτυπικά (δηλαδή: τα προφίλ έκφρασης των δύο κυττάρων είναι διαφορετικά).\n",
    "\n",
    "- Επομένως έχουμε μεταγραφωματικά προφίλ τα οποία ενώ φαίνεται ότι έχουν προέλθει από ένα κύτταρο, στην πράξη έχουν προέλθει από τον συνδυασμό δύο κυττάρων (κάτι το οποίο μπορεί να οδηγήσει σε εσφαλμένα συμπεράσματα).\n",
    "\n",
    "- Έχουν προταθεί μεθοδολογίες βασισμένες σε μηχανική μάθηση, μέσω των οποίων γίνεται ταυτοποίηση και αφαίρεση των doublets (doublet finder, solo, κλπ). Οι μεθοδολογίες αυτές αποτελούνται από τα ίδια βασικά βήματα:\n",
    "\n",
    "     - 1) Προσομοίωση \"τεχνητών\" doublets από τα κύτταρα του dataset (τα οποία είναι ένα μείγμα από singlets και               doublets).\n",
    "     - 2) Εκπαίδευση ενός ταξινομητή έτσι ώστε να εντοπίζει τα \"τεχνητά\" doublets.\n",
    "     - 3) Εφαρμογή του ταξινομητή στο πραγματικό σύνολο δεδομένων για πρόβλεψη και αφαίρεση των doublets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d63f0f",
   "metadata": {},
   "source": [
    "- Το SOLO δημιουργεί \"τεχνητά\" doublets όπως και το doublet finder. Γίνεται τυχαία δειγματοληψία ζευγών κυττάρων και αφού αθροιστούν τα προφίλ έκφρασης τους στη συνέχεια γίνεται διαίρεση με το 2. Η διαδικασία αυτή γίνεται επαναλήπτικά έτσι ώστε να δημιουργηθούν N \"τεχνητά\" doublets.\n",
    "\n",
    "- Η εκπαίδευση του ταξιξομητή αφορά στη διάκριση μεταξύ των \"τεχνητών\" doublets και των πραγματικών δεδομένων γονιδιακής έκφρασης. \n",
    "\n",
    "- Λαμβάνει χώρα σε έναν χώρο χαρακτηριστικών μειωμένης διαστατικότητας ο οποίος είναι μη-γραμμικός (έχει προκύψει από ένα variational autoencoder της βιβλιοθήκης scVI).\n",
    "\n",
    "- Ο ταξινομητή που χρησιμοποιείται για την εύρεση των doublets είναι ένα τεχνητό νευρωνικό δίκτυο της βιβλιοθήκης scVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf2ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_doublets(directory=\"./data/3.H5AD_filtered\"):\n",
    "    # List all files in the specified directory\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".h5ad\"):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(directory, file)\n",
    "            # Print the file name\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "\n",
    "            adata = sc.read_h5ad(file_path)\n",
    "            sc.pp.highly_variable_genes(adata, n_top_genes=3000, subset=True, flavor=\"seurat_v3\", span=0.8)\n",
    "            scvi.model.SCVI.setup_anndata(adata)\n",
    "            vae = scvi.model.SCVI(adata)\n",
    "            vae.train()\n",
    "            solo = scvi.external.SOLO.from_scvi_model(vae)\n",
    "            solo.train()\n",
    "            df = solo.predict()\n",
    "            df[\"prediction\"] = solo.predict(soft=False)\n",
    "\n",
    "            doublet_dic = dict(zip(df.index, df.prediction))\n",
    "\n",
    "            def filter_doublet(x):\n",
    "                try:\n",
    "                    return doublet_dic[x]\n",
    "                except:\n",
    "                    return 'filtered'\n",
    "\n",
    "            adata = sc.read_h5ad(file_path)\n",
    "            adata.obs[\"doublet\"] = adata.obs.index.map(filter_doublet)\n",
    "            adata = adata[adata.obs.doublet == 'singlet']\n",
    "            adata.write_h5ad(\n",
    "                        f\"./data/4.H5AD_filtered_without_doublets/fwd_{file}\",\n",
    "                        compression=hdf5plugin.FILTERS[\"zstd\"]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7215f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./data/3.H5AD_filtered/filtered_GSM4432635_Control.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████████████| 400/400 [01:20<00:00,  5.12it/s, v_num=1, train_loss_step=1.3e+3, train_loss_epoch=1.2e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████████████| 400/400 [01:20<00:00,  4.96it/s, v_num=1, train_loss_step=1.3e+3, train_loss_epoch=1.2e+3]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/400:  64%|████████████▋       | 254/400 [00:39<00:22,  6.51it/s, v_num=1, train_loss_step=0.338, train_loss_epoch=0.257]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.243. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./data/3.H5AD_filtered/filtered_GSM4432637_Control.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|████████████████████████| 400/400 [00:37<00:00, 10.68it/s, v_num=1, train_loss_step=776, train_loss_epoch=775]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|████████████████████████| 400/400 [00:37<00:00, 10.68it/s, v_num=1, train_loss_step=776, train_loss_epoch=775]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/400:  60%|████████████        | 241/400 [00:18<00:11, 13.38it/s, v_num=1, train_loss_step=0.202, train_loss_epoch=0.181]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.259. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./data/3.H5AD_filtered/filtered_GSM4432638_Alzheimer.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|████████████████| 400/400 [01:09<00:00,  5.78it/s, v_num=1, train_loss_step=1.01e+3, train_loss_epoch=1.02e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|████████████████| 400/400 [01:09<00:00,  5.75it/s, v_num=1, train_loss_step=1.01e+3, train_loss_epoch=1.02e+3]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/400:  73%|██████████████▋     | 293/400 [00:40<00:14,  7.16it/s, v_num=1, train_loss_step=0.413, train_loss_epoch=0.232]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.237. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./data/3.H5AD_filtered/filtered_GSM4432636_Control.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|████████████████████████| 400/400 [00:28<00:00, 14.33it/s, v_num=1, train_loss_step=968, train_loss_epoch=966]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|████████████████████████| 400/400 [00:28<00:00, 14.21it/s, v_num=1, train_loss_step=968, train_loss_epoch=966]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/400:  78%|███████████████▋    | 313/400 [00:17<00:04, 18.18it/s, v_num=1, train_loss_step=0.391, train_loss_epoch=0.208]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.236. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./data/3.H5AD_filtered/filtered_GSM4432639_Alzheimer.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|████████████████████████| 400/400 [00:47<00:00,  8.38it/s, v_num=1, train_loss_step=793, train_loss_epoch=811]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|████████████████████████| 400/400 [00:47<00:00,  8.44it/s, v_num=1, train_loss_step=793, train_loss_epoch=811]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/400:  87%|█████████████████▎  | 347/400 [00:32<00:04, 10.61it/s, v_num=1, train_loss_step=0.0979, train_loss_epoch=0.16]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.167. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./data/3.H5AD_filtered/filtered_GSM4432641_Alzheimer.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|████████████████| 400/400 [01:28<00:00,  4.53it/s, v_num=1, train_loss_step=1.34e+3, train_loss_epoch=1.33e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|████████████████| 400/400 [01:28<00:00,  4.54it/s, v_num=1, train_loss_step=1.34e+3, train_loss_epoch=1.33e+3]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/400:  70%|██████████████      | 281/400 [00:48<00:20,  5.78it/s, v_num=1, train_loss_step=0.193, train_loss_epoch=0.215]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.215. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./data/3.H5AD_filtered/filtered_GSM4432640_Alzheimer.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|████████████████| 400/400 [00:15<00:00, 26.07it/s, v_num=1, train_loss_step=1.49e+3, train_loss_epoch=1.41e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|████████████████| 400/400 [00:15<00:00, 26.01it/s, v_num=1, train_loss_step=1.49e+3, train_loss_epoch=1.41e+3]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310/400:  78%|███████████████▌    | 310/400 [00:09<00:02, 31.88it/s, v_num=1, train_loss_step=0.238, train_loss_epoch=0.304]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.376. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostas/miniconda3/envs/scrna/lib/python3.9/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    }
   ],
   "source": [
    "filter_doublets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a02e67a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
